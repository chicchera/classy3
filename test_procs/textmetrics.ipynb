{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d26856-4a28-4321-9f4a-3112a0fd0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from rich import print\n",
    "import inspect\n",
    "import os\n",
    "from collections import Counter\n",
    "import re\n",
    "import textstat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008cf029-3bff-4f35-a424-f1b879d8626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = '/home/silvio/miniconda3/envs/classy3/prg/config/'\n",
    "STOPWORD_ES = 'stopwords_es.txt'\n",
    "STOPWORD_RED = 'stopwords_reddit.txt'\n",
    "DICTIONARY = 'new_dic.txt'\n",
    "\n",
    "dictionary = os.path.join(CONFIG_DIR, DICTIONARY)\n",
    "stopwords_files = [os.path.join(CONFIG_DIR, STOPWORD_ES),\n",
    "                  os.path.join(CONFIG_DIR,STOPWORD_RED)]\n",
    "# stop_words_es = os.path.join(CONFIG_DIR, STOPWORD_ES)\n",
    "# stop_words_red = os.path.join(CONFIG_DIR,STOPWORD_RED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57c90dd-b851-4727-a0b4-61bb28749a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Textmetrics:\n",
    "    def __init__(self, lang=\"es\", steps=10):\n",
    "        self._lang = lang\n",
    "        self._textstats = textstat\n",
    "        self._textstats.set_lang(lang)\n",
    "        self._dictionary_file = None\n",
    "        self._dictionary = None\n",
    "        self._dictionay_terms = 0\n",
    "        self._dictionary_steps = steps\n",
    "        self._dictionary_thresholds = []\n",
    "        self._stopwords = Counter()\n",
    "        self._stopwords_files = []\n",
    "        self._misspellings = []\n",
    "        self._num_words = 0\n",
    "        self._num_stopwords = 0\n",
    "        self._text = \"\"\n",
    "\n",
    "    def get_frequency(line_num):\n",
    "        \"\"\"\n",
    "            When splitting the dictionary for creating the steps,\n",
    "            it reads a specific line of the dictionary and returns the\n",
    "            frequency of the associated word.\n",
    "            SymSpell returns the original word, or the correction, toghether\n",
    "            with the frequency: this number will be usde to classify the difficulty\n",
    "            of a word.\n",
    "        \"\"\"\n",
    "        line = linecache.getline(self._dictionary_file, line_num)\n",
    "        if line:\n",
    "            words = line.split()\n",
    "            if len(words) >= 2:\n",
    "                second_word = words[1]\n",
    "                try:\n",
    "                    second_word_as_int = int(second_word)\n",
    "                except ValueError:\n",
    "                    print(\"Second word is not an integer.\")\n",
    "            else:\n",
    "                print(\"Line doesn't contain at least two words.\")\n",
    "        return second_word_as_int\n",
    "        \n",
    "\n",
    "    def stat(self, function_name):\n",
    "        \"\"\"\n",
    "            applies the textstat routine specified in function_name\n",
    "            to self._textand and returns the result\n",
    "            Is like calling self._textstats.function_name(self._text)\n",
    "            but allows to decouple the two objects\n",
    "        \"\"\"\n",
    "        # Check if the function_name exists in textstat\n",
    "        if hasattr(self._textstats, function_name) and callable(getattr(self._textstats, function_name)):\n",
    "            # Call the function dynamically with self._text as a parameter\n",
    "            func = getattr(self._textstats, function_name)\n",
    "            result = func(self._text)\n",
    "            return result\n",
    "        else:\n",
    "            # Handle the case where the function doesn't exist\n",
    "            return \"Function not found\"\n",
    "\n",
    "    @property\n",
    "    def stopwords_files(self):\n",
    "        return self._stopwords_files\n",
    "    \n",
    "    @stopwords_files.setter\n",
    "    def stopwords_files(self, files_list):\n",
    "        \"\"\"\n",
    "            Loads stopwords rom as many file as are contained in files_list.\n",
    "            The purpose is to allow stopwords for specifica fields to be loaded.\n",
    "            For example, if it were a medical supplement to the standard stopwords,\n",
    "            it would contain words like, hospital, IV, transfusion, ER, OR,  nurse, injection, etc\n",
    "            NOTE: we are talking about stopwords, that is, words that are considered imprescindible\n",
    "            to read and understand a medical text, but they could be important \n",
    "            to analize the content.\n",
    "        \"\"\"\n",
    "        self._stopwords_files = files_list\n",
    "        self._stopwords = Counter()\n",
    "        for file_path in self._stopwords_files:\n",
    "            try:\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    lines = file.readlines()\n",
    "                    # Update the Counter with words (stripped of whitespace and newline characters)\n",
    "                    for line in lines:\n",
    "                        word = line.strip()\n",
    "                        if word:\n",
    "                            self._stopwords.update([word.lower()])\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while reading {file_path}: {str(e)}\")\n",
    "\n",
    "        # self._stopwords = stopwords\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    _text contains the string for which we want statistics in general\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def text(self):\n",
    "        return self._text\n",
    "    \n",
    "    @text.setter\n",
    "    def text(self, txt):\n",
    "        self._text = txt\n",
    "\n",
    "    \"\"\"\n",
    "    _dictionary_steps containes the blocks into which we want to split the dictionary.\n",
    "    As an example, let's say that we divide a dictionay in 10 parts with the purpose\n",
    "    of assessing students from first to tenth grade. In first grade the should be able to \n",
    "    understand words extracted from the first part of the dictionry, and the same applies\n",
    "    to students of the fifth grade.\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def dictionary_steps(self):\n",
    "        return self._dictionary_steps\n",
    "    \n",
    "    @dictionary_steps.setter\n",
    "    def dictionary_steps(self, number_of_steps):\n",
    "        self._dictionary_steps = number_of_steps\n",
    "\n",
    "    #TODO: add the possibility to merg two dictionaries\n",
    "    #TODO: add the possibility to insert specialized dictionaries at a given position\n",
    "    @property\n",
    "    def dictionary_file(self):\n",
    "        return self._dictionary\n",
    "\n",
    "    @dictionary_file.setter\n",
    "    def dictionary_file(self, file):\n",
    "        self._dictionary_file = file\n",
    "        with open(file, \"rbU\") as f:\n",
    "            self._dictionay_terms = sum(1 for _ in f)\n",
    "        self._dictionary_block_size = self._dictionay_terms //  self._dictionary_steps\n",
    "        \n",
    "        line_numbers = []\n",
    "        thresholds = []\n",
    "        for i in range(1, self._dictionary_steps):\n",
    "            line_numbers.append(dictionary_block_size * i)\n",
    "            self._dictionary_thresholds.append(get_frequency(self._dictionary_steps))\n",
    "        self._dictionary_thresholds.append(self._dictionay_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5610dae-90a8-4301-8919-823ff564b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = Textmetrics(lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ce7d4d-9fb2-419a-9b30-18ea75f63cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.stopwords_files = stopwords_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3873e66d-c868-426e-aeba-4f2ca24f35a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/silvio/miniconda3/envs/classy3/prg/config/stopwords_es.txt'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/silvio/miniconda3/envs/classy3/prg/config/stopwords_reddit.txt'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'/home/silvio/miniconda3/envs/classy3/prg/config/stopwords_es.txt'\u001b[0m,\n",
       "    \u001b[32m'/home/silvio/miniconda3/envs/classy3/prg/config/stopwords_reddit.txt'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tm.stopwords_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bde92e1-dc0e-4b63-b7bf-7299b2ffe429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tm.text = \"Nunca jamás\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30529a74-dde5-47cb-bd90-c49e3a515f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Nunca jamás\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Nunca jamás\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tm.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad6799-139b-48c7-a58d-367c94c2b9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
